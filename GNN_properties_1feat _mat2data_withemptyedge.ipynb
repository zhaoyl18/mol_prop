{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e5939cb-44bc-4475-8e9e-d693603e1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import warnings\n",
    "from typing import Callable, Union\n",
    "from enum import Enum\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch_geometric.nn import GATConv, global_add_pool, GINEConv, GlobalAttention, JumpingKnowledge\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import torchmetrics\n",
    "from torch.utils.data import Dataset\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.loggers import Logger\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import networkx as nx\n",
    "import rdkit.Chem\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from torch_geometric import nn as geo_nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35003660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set CUDA_VISIBLE_DEVICES to the 5th GPU (index 4, since indexing starts at 0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04552d89-7c98-4a37-a729-f4ec631a8b39",
   "metadata": {},
   "source": [
    "# define all the necessary modulesdefaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bbc641f-1140-40ec-b256-15a964792265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNEPropTask(Enum):\n",
    "    BINARY_CLASSIFICATION = 'binary_classification'\n",
    "    REGRESSION = 'regression'\n",
    "    MULTI_CLASSIFICATION = 'multi_classification'\n",
    "\n",
    "    def get_metrics(self) -> list[str]:\n",
    "        if self.value in ('binary_classification', 'multi_classification'):\n",
    "            return ['auc', 'ap', 'acc']\n",
    "        elif self.value == 'regression':\n",
    "            return ['mse', 'mae']\n",
    "\n",
    "    def get_default_metric(self) -> str:\n",
    "        if self.value in ('binary_classification', 'multi_classification'):\n",
    "            return 'auc'\n",
    "        elif self.value == 'regression':\n",
    "            return 'mse'\n",
    "\n",
    "    @staticmethod\n",
    "    def validation_names(m) -> Union[str, list[str]]:\n",
    "        if isinstance(m, str):\n",
    "            return 'val/' + m\n",
    "        elif isinstance(m, Sequence):\n",
    "            return ['val/' + i for i in m]\n",
    "\n",
    "\n",
    "class GNNMolEncoder(nn.Module):\n",
    "    def __init__(self, node_dim: int, edge_dim: int, hidden_dim_graph: int, hidden_dim_ffn: int, num_mp_layers: int,\n",
    "                 num_readout_layers: int,\n",
    "                 out_channels: int,\n",
    "                 dropout: float, aggr: str = 'mean', jk: str = 'cat'):\n",
    "        super().__init__()\n",
    "\n",
    "        # graph encoder\n",
    "        self.node_encoder = nn.Linear(node_dim, hidden_dim_graph)\n",
    "        self.edge_encoder = nn.Linear(edge_dim, hidden_dim_graph)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        for _ in range(num_mp_layers):\n",
    "            mlp = nn.Sequential(\n",
    "                nn.Linear(hidden_dim_graph, 2 * hidden_dim_graph),\n",
    "                nn.BatchNorm1d(2 * hidden_dim_graph),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(2 * hidden_dim_graph, hidden_dim_graph),\n",
    "                nn.BatchNorm1d(hidden_dim_graph),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=dropout)\n",
    "            )\n",
    "            conv = GINEConv(mlp, train_eps=True)\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.jk_mode = jk\n",
    "        if self.jk_mode == 'none':\n",
    "            self.jk = None\n",
    "        else:\n",
    "            self.jk = JumpingKnowledge(mode=self.jk_mode, channels=hidden_dim_graph, num_layers=num_mp_layers)\n",
    "\n",
    "        # global pooling\n",
    "        self.aggr = aggr\n",
    "        if aggr == 'mean':\n",
    "            self.global_pool = global_mean_pool\n",
    "        elif aggr == 'sum':\n",
    "            self.global_pool = global_add_pool\n",
    "\n",
    "        # classifier\n",
    "        self.classifier = nn.ModuleList()\n",
    "\n",
    "        if self.jk_mode == 'none':\n",
    "            hidden_channels_mol = hidden_dim_graph\n",
    "        elif self.jk_mode == 'cat':\n",
    "            hidden_channels_mol = hidden_dim_graph * (num_mp_layers + 1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        for layer in range(num_readout_layers):\n",
    "            input_dim = hidden_channels_mol if layer == 0 else hidden_dim_ffn\n",
    "            mlp = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim_ffn),\n",
    "                nn.BatchNorm1d(hidden_dim_ffn),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=dropout),\n",
    "            )\n",
    "            self.classifier.append(mlp)\n",
    "\n",
    "        # last layer (classifier)\n",
    "        input_dim_classifier = hidden_channels_mol if num_readout_layers == 0 else hidden_dim_ffn\n",
    "        self.classifier.append(nn.Linear(input_dim_classifier, out_channels), )\n",
    "\n",
    "    def compute_message_passing(self, data: torch_geometric.data.Data) -> torch.Tensor:\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        list_graph_encodings = []\n",
    "\n",
    "        x_encoded = self.node_encoder(x)\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        if self.jk_mode != 'none':\n",
    "            list_graph_encodings.append(x_encoded)\n",
    "        for conv in self.convs:\n",
    "            x_encoded = conv(x_encoded, edge_index, edge_attr)\n",
    "            if self.jk_mode != 'none':\n",
    "                list_graph_encodings.append(x_encoded)\n",
    "\n",
    "        if self.jk_mode != 'none':\n",
    "            x_encoded = self.jk(list_graph_encodings)\n",
    "\n",
    "        out = self.global_pool(x_encoded, batch)  # [batch_size, hidden_channels]\n",
    "        return out\n",
    "\n",
    "    def compute_readout(self, graph_repr: torch.Tensor, restrict_output_layers: int = 0) -> torch.Tensor:\n",
    "        out = graph_repr\n",
    "        for mlp in self.classifier[:None if restrict_output_layers == 0 else restrict_output_layers]:\n",
    "            out = mlp(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, data: torch_geometric.data.Data) -> torch.Tensor:\n",
    "        graph_repr = self.compute_message_passing(data)\n",
    "        out = self.compute_readout(graph_repr)\n",
    "        return out\n",
    "\n",
    "\n",
    "def predict_ensemble(list_checkpoints: list[str], data: Union[torch.utils.data.Dataset, torch.utils.data.DataLoader],\n",
    "                     aggr: str = 'mean',\n",
    "                     gpus: int = 1) -> tuple[np.ndarray, np.ndarray]:\n",
    "    # works only for single input\n",
    "    all_preds = []\n",
    "    for checkpoint in list_checkpoints:\n",
    "        print(f'Predicting checkpoint <{checkpoint}>...')\n",
    "        model = MoleculeModel.load_from_checkpoint(checkpoint)\n",
    "        preds = model.predict_data(data, gpus=gpus).flatten()\n",
    "        all_preds.append(preds)\n",
    "\n",
    "    all_res = np.stack(all_preds)  # n_ensemble x n_mols\n",
    "    if aggr == 'mean':\n",
    "        preds, epi_uncs = all_res.mean(axis=0), all_res.var(axis=0)\n",
    "    elif aggr == 'max':\n",
    "        preds, epi_uncs = all_res.max(axis=0), all_res.var(axis=0)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return preds, epi_uncs\n",
    "\n",
    "\n",
    "def predict_from_checkpoints(data: Union[str, torch.utils.data.Dataset, torch.utils.data.DataLoader],\n",
    "                             checkpoint_path: str = None, checkpoints_paths: list[str] = None,\n",
    "                             checkpoint_dir: str = None, aggr: str = 'mean', gpus: int = 1) -> tuple[\n",
    "    np.ndarray, np.ndarray]:\n",
    "    list_checkpoints = get_checkpoint_paths(checkpoint_path=checkpoint_path,\n",
    "                                            checkpoint_paths=checkpoints_paths,\n",
    "                                            checkpoint_dir=checkpoint_dir)\n",
    "    return predict_ensemble(list_checkpoints, data, aggr=aggr, gpus=gpus)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MoleculeModel(L.LightningModule):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = GNNMolEncoder(node_dim=self.hparams.node_dim,\n",
    "                                     edge_dim=self.hparams.edge_dim,\n",
    "                                     hidden_dim_graph=self.hparams.hidden_dim_graph,\n",
    "                                     hidden_dim_ffn=self.hparams.hidden_dim_ffn,\n",
    "                                     num_mp_layers=self.hparams.num_mp_layers,\n",
    "                                     num_readout_layers=self.hparams.num_readout_layers,\n",
    "                                     out_channels=self.hparams.out_channels,\n",
    "                                     dropout=self.hparams.dropout,\n",
    "                                     aggr=self.hparams.aggr,\n",
    "                                     jk=self.hparams.jk, )\n",
    "\n",
    "        self.task = GNEPropTask(self.hparams.task)\n",
    "        if self.task not in (GNEPropTask.BINARY_CLASSIFICATION,GNEPropTask.REGRESSION):\n",
    "            raise ValueError(f\"Unsupported task: {self.task}\")\n",
    "\n",
    "        self.loss_function = self.get_loss_func()\n",
    "\n",
    "        self.metrics = self.get_metrics()\n",
    "\n",
    "    def get_metrics(self) -> dict[str, Callable[[torch.tensor, torch.tensor], torch.tensor]]:\n",
    "        metrics = dict()\n",
    "        if self.task is GNEPropTask.BINARY_CLASSIFICATION:\n",
    "            metrics['auc'] = torchmetrics.classification.BinaryAUROC()\n",
    "            metrics['auprc'] = torchmetrics.classification.BinaryAveragePrecision()\n",
    "            metrics['accuracy'] = torchmetrics.classification.BinaryAccuracy()\n",
    "            metrics['precision'] = torchmetrics.classification.BinaryPrecision()\n",
    "            metrics['recall'] = torchmetrics.classification.BinaryRecall()\n",
    "        elif self.task is GNEPropTask.REGRESSION:\n",
    "            metrics['mse'] = torchmetrics.regression.MeanSquaredError(num_outputs=self.hparams.out_channels)\n",
    "            metrics['mae'] = torchmetrics.regression.MeanAbsoluteError()\n",
    "            metrics['r2'] = torchmetrics.regression.R2Score(num_outputs=self.hparams.out_channels)\n",
    "            metrics['pearson_coef'] = torchmetrics.regression.PearsonCorrCoef(num_outputs=self.hparams.out_channels)\n",
    "            metrics['spearman_coef'] = torchmetrics.regression.SpearmanCorrCoef(num_outputs=self.hparams.out_channels)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def get_loss_func(self):\n",
    "        if self.task is GNEPropTask.BINARY_CLASSIFICATION:\n",
    "            if self.hparams.pos_weight != 1:\n",
    "                loss_function = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.hparams.pos_weight))\n",
    "            else:\n",
    "                loss_function = nn.BCEWithLogitsLoss()\n",
    "        elif self.task is GNEPropTask.REGRESSION:\n",
    "            loss_function = nn.MSELoss()\n",
    "        elif self.task is GNEPropTask.MULTI_CLASSIFICATION:\n",
    "            if self.hparams.class_weight is None:\n",
    "                loss_function = nn.CrossEntropyLoss()\n",
    "            else:\n",
    "                loss_function = nn.CrossEntropyLoss(weight=torch.tensor(self.hparams.class_weight))\n",
    "\n",
    "        return loss_function\n",
    "\n",
    "    def forward(self, data: torch_geometric.data.Data) -> torch.Tensor:\n",
    "        o = self._compute_with_activation(data, return_logits=False)\n",
    "        return o\n",
    "\n",
    "    def _compute_with_activation(self, data: torch_geometric.data.Data, return_logits: bool = False) -> Union[\n",
    "        torch.Tensor, tuple[torch.Tensor, torch.Tensor]]:\n",
    "        logits = self.encoder(data)\n",
    "\n",
    "        if self.task is GNEPropTask.BINARY_CLASSIFICATION:\n",
    "            o = torch.sigmoid(logits)\n",
    "        elif self.task is GNEPropTask.REGRESSION:\n",
    "            o = F.relu(logits) if self.hparams.final_relu else logits\n",
    "        elif self.task is GNEPropTask.MULTI_CLASSIFICATION:\n",
    "            o = torch.softmax(logits, dim=1)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        return o, logits if return_logits else o\n",
    "\n",
    "    def _compute_loss(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        loss = self.loss_function(logits, targets)\n",
    "        return loss\n",
    "\n",
    "    def _prepare_labels(self, targets: torch.Tensor) -> torch.Tensor:\n",
    "        if self.task is GNEPropTask.MULTI_CLASSIFICATION:\n",
    "            targets = targets.long()\n",
    "\n",
    "        return targets\n",
    "\n",
    "    def _prepare_labels_return(self, targets: torch.Tensor) -> torch.Tensor:\n",
    "        if self.task in (GNEPropTask.BINARY_CLASSIFICATION, GNEPropTask.MULTI_CLASSIFICATION):\n",
    "            targets = targets.long()\n",
    "        return targets\n",
    "\n",
    "    def compute_step(self, batch: torch_geometric.data.Data, prefix: str) -> torch.Tensor:\n",
    "        y = batch.y\n",
    "        y = self._prepare_labels(y)\n",
    "\n",
    "        outputs, logits = self._compute_with_activation(batch, return_logits=True)\n",
    "        loss = self._compute_loss(logits, y)\n",
    "\n",
    "        self.log(f\"{prefix}/loss\", loss, prog_bar=True, batch_size=batch.y.shape[0])\n",
    "\n",
    "        y = self._prepare_labels_return(y)\n",
    "\n",
    "        # print metrics\n",
    "        for metric_name, metric_func in self.metrics.items():\n",
    "            self.log(f\"{prefix}/{metric_name}\", metric_func(outputs, y).mean(), prog_bar=True, batch_size=batch.y.shape[0])\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch: torch_geometric.data.Data, batch_idx) -> torch.Tensor:\n",
    "        batch = batch['train']\n",
    "        return self.compute_step(batch, prefix=\"train\")\n",
    "\n",
    "    def validation_step(self, batch: torch_geometric.data.Data, batch_idx) -> torch.Tensor:\n",
    "        return self.compute_step(batch, prefix=\"val\")\n",
    "\n",
    "    def test_step(self, batch: torch_geometric.data.Data, batch_idx) -> torch.Tensor:\n",
    "        return self.compute_step(batch, prefix=\"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.wd,\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        # fix metrics devices\n",
    "        for k, v in self.metrics.items():\n",
    "            self.metrics[k] = v.to(self.device)\n",
    "\n",
    "    def on_test_start(self):\n",
    "        # fix metrics devices\n",
    "        for k, v in self.metrics.items():\n",
    "            self.metrics[k] = v.to(self.device)\n",
    "\n",
    "    def predict_data(self, dataset: torch.utils.data.Dataset, gpus: int = 1, batch_size: int = 100,\n",
    "                     num_workers: int = 16):\n",
    "        trainer = L.Trainer(devices=gpus, logger=False)\n",
    "        dataloader = convert_to_dataloader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "        res = trainer.predict(self, dataloaders=dataloader)\n",
    "        res = [i[0].cpu().numpy() for i in res]\n",
    "        res = np.concatenate(res)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def test_data(self, dataset: torch.utils.data.Dataset, gpus: int = 1, batch_size: Union[str, int] = 'full',\n",
    "                  num_workers: int = 16):\n",
    "        if batch_size == 'full':\n",
    "            batch_size = len(dataset)\n",
    "        trainer = L.Trainer(devices=gpus, logger=False)\n",
    "        dataloader = convert_to_dataloader(dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "        trainer.test(self, dataloaders=dataloader)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_from_directory(dir_path: str):\n",
    "        \"\"\"\n",
    "        Assumes only one checkpoint exists in the directory\n",
    "        :param self:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        paths = get_checkpoint_paths(checkpoint_dir=dir_path)\n",
    "        if len(paths) > 1:\n",
    "            warnings.warn(f\"Found {len(paths)} checkpoints, one selected randomly\", UserWarning)\n",
    "        elif len(paths) == 0:\n",
    "            raise ValueError(\"No checkpoints found\")\n",
    "        else:\n",
    "            return MoleculeModel.load_from_checkpoint(paths[0])\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"MoleculeModel\")\n",
    "        parser.add_argument('--node_dim', type=int, default=133)\n",
    "        parser.add_argument('--edge_dim', type=int, default=12)\n",
    "        parser.add_argument('--hidden_dim_graph', type=int, default=100)\n",
    "        parser.add_argument('--hidden_dim_ffn', type=int, default=100)\n",
    "        parser.add_argument('--num_mp_layers', type=int, default=5)\n",
    "        parser.add_argument('--num_readout_layers', type=int, default=2)\n",
    "        parser.add_argument('--dropout', type=float, default=0.)\n",
    "        parser.add_argument('--lr', type=float, default=5.e-05)\n",
    "        parser.add_argument('--wd', type=float, default=0.)\n",
    "        parser.add_argument('--aggr', default='mean', const='mean', nargs='?',\n",
    "                            choices=['mean', 'sum'])\n",
    "        parser.add_argument('--jk', default='cat', const='cat', nargs='?', choices=['cat', 'none'])\n",
    "        parser.add_argument('--task', default='binary_classification', const='binary_classification', nargs='?',\n",
    "                            choices=[i.value for i in GNEPropTask], help='GNEprop task')\n",
    "        parser.add_argument('--pos_weight', type=int, default=1, help='Loss weight for binary classification.')\n",
    "        parser.add_argument(\"--weight_decay\", type=float, default=0.)\n",
    "        parser.add_argument('--out_channels', type=int, default=1,\n",
    "                            help='Output size')\n",
    "        # parser.add_argument('--lr_strategy', default='constant', const='constant',\n",
    "        #                     nargs='?',\n",
    "        #                     choices=['constant', 'warmup_cosine'])\n",
    "        parser.add_argument('--final_relu', action=\"store_true\", help='Toggle final relu activation for regression')\n",
    "        parser.add_argument(\"--metric\", type=str, default='val/auc')\n",
    "        return parent_parser\n",
    "\n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        print(f\"Epoch {self.current_epoch} done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa334c6a-a3a1-4115-81b7-fbda60ea5f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_networkx(smiles, kekulize=True):\n",
    "    \"\"\"\n",
    "    Converts a SMILES string to a NetworkX graph. The graph will retain the\n",
    "    atomic number and bond type for nodes and edges (respectively), under the\n",
    "    keys `atomic_num` and `bond_type` (respectively).\n",
    "    Arguments:\n",
    "        `smiles`: a SMILES string\n",
    "        `kekulize`: if True, denote single/double bonds separately in aromatic\n",
    "            structures instead of using the aromatic bond type\n",
    "    Returns a NetworkX graph.\n",
    "    \"\"\"\n",
    "    mol = rdkit.Chem.MolFromSmiles(smiles)\n",
    "    if kekulize:\n",
    "        rdkit.Chem.Kekulize(mol)\n",
    "    g = nx.Graph()\n",
    "    for atom in mol.GetAtoms():\n",
    "        g.add_node(\n",
    "            atom.GetIdx(),\n",
    "            atomic_num=atom.GetAtomicNum()\n",
    "        )\n",
    "    for bond in mol.GetBonds():\n",
    "        g.add_edge(\n",
    "            bond.GetBeginAtomIdx(),\n",
    "            bond.GetEndAtomIdx(),\n",
    "            bond_type=bond.GetBondType()\n",
    "        )\n",
    "    return g\n",
    "\n",
    "\n",
    "MAX_NUM_NODES = 38\n",
    "ATOM_MAP = torch.tensor([6, 7, 8, 9, 16, 17, 35, 53, 15])\n",
    "BOND_TYPE_MAP = {\n",
    "    0: 0, 1: 1, 2: 2, 3: 3, 12: 1.5,  # setting aromatic bonds to 1.5\n",
    "}\n",
    "\n",
    "def smiles_to_data(\n",
    "    smiles: str,\n",
    ") -> Data:\n",
    "    graph = smiles_to_networkx(smiles)\n",
    "    for edge_idx in graph.edges():\n",
    "        edge = graph.edges[edge_idx]\n",
    "        edge[\"bond_type\"] = BOND_TYPE_MAP[edge[\"bond_type\"]]\n",
    "        \n",
    "    for i, j in product(range(len(graph)), range(len(graph))):\n",
    "        if i == j or (i, j) in graph.edges():\n",
    "            continue\n",
    "        graph.add_edge(i, j, bond_type=0)\n",
    "    data = torch_geometric.utils.from_networkx(graph)\n",
    "    data.x = (data.atomic_num.unsqueeze(1) == ATOM_MAP.unsqueeze(0)).float()  #(num_node,9)\n",
    "    \n",
    "    # data.edge_attr = F.one_hot(data.bond_type, num_classes=4).to(torch.float32)\n",
    "    data.edge_attr = data.bond_type.view(-1, 1).to(torch.float32)   #(num_edge,1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "class MolData(Dataset):\n",
    "    def __init__(\n",
    "        self, smiles: list[str], y: np.ndarray,\n",
    "    ):\n",
    "        assert len(y) == len(smiles)\n",
    "        self.smiles = smiles\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.smiles)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Data:\n",
    "        data = smiles_to_data(self.smiles[idx])\n",
    "        \n",
    "        data.y = self.y[idx: idx + 1].clone()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3f6b2-eb95-4afd-acd5-e55ae2c85226",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5134fd41-ed5d-4f54-b4a1-d74a0269ff42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3681629/4167676812.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y, dtype=torch.float32)\n",
      "/data/yulai/anaconda3/envs/mol/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/aspuru-guzik-group/chemical_vae/master/models/zinc_properties/250k_rndm_zinc_drugs_clean_3.csv\")\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    df[\"smiles\"].values, df[[\"qed\"]].values, random_state=13141,\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, random_state=11, test_size=0.1,\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_val = scaler.transform(y_val)\n",
    "y_test = scaler.transform(y_test)\n",
    "\n",
    "train_dset = MolData(\n",
    "    X_train, torch.tensor(y_train, dtype=torch.float32),\n",
    ")\n",
    "val_dset = MolData(\n",
    "    X_val, torch.tensor(y_val, dtype=torch.float32),\n",
    ")\n",
    "test_dset = MolData(\n",
    "    X_test, torch.tensor(y_test, dtype=torch.float32),\n",
    ")\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "train_loader = DataLoader(\n",
    "    train_dset, batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dset, batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dset, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546fd50e-0e0d-4dcb-900f-db7b7603bb6d",
   "metadata": {},
   "source": [
    "# prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc40e6e1-7424-4319-95fb-e7e7c40e3f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yulai/anaconda3/envs/mol/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "parser = ArgumentParser()\n",
    "MoleculeModel.add_model_specific_args(parser)\n",
    "args = parser.parse_args(\"\")\n",
    "args.node_dim = 9\n",
    "args.edge_dim = 1\n",
    "args.lr = 1e-5\n",
    "args.task = \"regression\"\n",
    "args.out_channels = 1\n",
    "model = MoleculeModel(**vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a47a69-d898-4832-8497-28b288fd249f",
   "metadata": {},
   "source": [
    "# check model has gradients w.r.t. node and edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4026c49-2e9a-47f6-bf73-e783b6e82df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2938, 9]), torch.Size([67184, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = next(train_loader.__iter__())\n",
    "d.edge_attr.requires_grad = True\n",
    "d.x.requires_grad = True\n",
    "out = model(d)[0].sum()\n",
    "gd = grad(out, [d.x, d.edge_attr])\n",
    "gd[0].shape, gd[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f53fc528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryLogger(Logger):\n",
    "    \"\"\"somewhat hacky way to use lightning to track metrics in memory for quick experiments\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.metrics = defaultdict(list)\n",
    "        self.hps = None\n",
    "\n",
    "    def log_metrics(self, metrics: dict[str, float], step: int = None):\n",
    "        for metric, value in metrics.items():\n",
    "            self.metrics[metric].append(value)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return \"in_memory_logger\"\n",
    "\n",
    "    def log_hyperparams(self, params: dict[str, float], **kwargs):\n",
    "        self.hps = params\n",
    "\n",
    "    @property\n",
    "    def version(self):\n",
    "        return \"0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a33ed9c-c48f-46a9-b53f-d61d8ef1b096",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e1faca-531e-47b9-8690-568c4819d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msarosavo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240403_062632-d1z822k6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sarosavo/mol_prop/runs/d1z822k6/workspace' target=\"_blank\">GNN_properties_1feat _mat2data_withemptyedge</a></strong> to <a href='https://wandb.ai/sarosavo/mol_prop' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sarosavo/mol_prop' target=\"_blank\">https://wandb.ai/sarosavo/mol_prop</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sarosavo/mol_prop/runs/d1z822k6/workspace' target=\"_blank\">https://wandb.ai/sarosavo/mol_prop/runs/d1z822k6/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yulai/anaconda3/envs/mol/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /data/yulai/projects/mol_prop/property_model/with_empty_edge/1feat exists and is not empty.\n",
      "Restoring states from the checkpoint path at property_model/with_empty_edge/1feat/epoch=16-step=1700.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | encoder       | GNNMolEncoder | 276 K \n",
      "1 | loss_function | MSELoss       | 0     \n",
      "------------------------------------------------\n",
      "276 K     Trainable params\n",
      "0         Non-trainable params\n",
      "276 K     Total params\n",
      "1.106     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at property_model/with_empty_edge/1feat/epoch=16-step=1700.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d760ece40047a9a549b13a361ba08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yulai/anaconda3/envs/mol/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1334ced496046e99d31b21b997bbba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dff6afb0cbe47fc94f50c62a8d08172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 done.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1e335067284cb98a6b799368545d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 100\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# logger = InMemoryLogger()\n",
    "logger = WandbLogger(name=\"GNN_properties_1feat _mat2data_withemptyedge\", project=\"mol_prop\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    limit_train_batches=100,\n",
    "    limit_val_batches=30,\n",
    "    log_every_n_steps=100,\n",
    "    logger=logger,\n",
    "    max_epochs=epochs,\n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[\n",
    "        LearningRateMonitor(),\n",
    "        EarlyStopping(monitor=\"val/loss\", mode=\"min\", patience=max(epochs // 10, 1)),\n",
    "        ModelCheckpoint(\n",
    "            \"./property_model/with_empty_edge/1feat/\",\n",
    "            monitor=\"val/loss\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "trainer.fit(\n",
    "    model=model, train_dataloaders={\"train\": train_loader}, val_dataloaders=val_loader, ckpt_path=\"property_model/with_empty_edge/1feat/epoch=16-step=1700.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45be08e-7038-4820-8a43-44090f1c17d5",
   "metadata": {},
   "source": [
    "# plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59f14c-2cb2-45db-864c-6799e01be618",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, vals in logger.metrics.items():\n",
    "    if not name.startswith(\"train/\"):\n",
    "        continue\n",
    "    plt.title(name[6:])\n",
    "    plt.plot(vals, label=\"train\")\n",
    "    plt.plot(logger.metrics[name.replace(\"train/\", \"val/\")], label=\"val\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "753a996e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72826449] [0.13956479]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/aspuru-guzik-group/chemical_vae/master/models/zinc_properties/250k_rndm_zinc_drugs_clean_3.csv\")\n",
    "X, y = df[\"smiles\"].values, df[[\"qed\"]].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "y_train = scaler.fit_transform(y)\n",
    "# y_val = scaler.transform(y_val)\n",
    "# y_test = scaler.transform(y_test)\n",
    "\n",
    "try:\n",
    "    mean_ = scaler.mean_\n",
    "    std_ = scaler.scale_\n",
    "except:\n",
    "    mean_ = 0\n",
    "    std_ = 1\n",
    "\n",
    "print(mean_, std_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6170325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3681629/4167676812.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y, dtype=torch.float32)\n",
      "/data/yulai/anaconda3/envs/mol/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/yulai/anaconda3/envs/mol/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c679a7dc6f4018ab03f274cd0428cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([111, 1])\n",
      "249455\n",
      "0.48962257618350835\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m Kernel \n",
      "\u001b[1;31m\n",
      "\u001b[1;31m<a href='https://aka.ms/vscodeJupyterKernelCrash'></a>\n",
      "\u001b[1;31m Jupyter <a href='command:jupyter.viewOutput'>log</a>"
     ]
    }
   ],
   "source": [
    "data_set = MolData(\n",
    "    X, torch.tensor(y, dtype=torch.float32),\n",
    ")\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "data_loader = DataLoader(\n",
    "    data_set, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    ")\n",
    "\n",
    "model = MoleculeModel.load_from_checkpoint(checkpoint_path=\"property_model/with_empty_edge/1feat/epoch=16-step=1700.ckpt\")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# For inference\n",
    "model.eval()    \n",
    "\n",
    "model_outputs = []  # List to store outputs\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "for batch in tqdm(data_loader):\n",
    "    batch = batch.to(DEVICE)\n",
    "    out = model(batch)\n",
    "    print(out[0].shape)\n",
    "    sys.stdout.flush()\n",
    "    model_outputs.extend(out[0].flatten().tolist())\n",
    "\n",
    "\n",
    "model_outputs = np.array(model_outputs) * std_ + mean_\n",
    "print(len(model_outputs))\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y, model_outputs)\n",
    "print(r2)\n",
    "\n",
    "# Plotting histogram of model outputs\n",
    "\n",
    "plt.hist(model_outputs, bins=50, alpha=0.5, label='predict')\n",
    "plt.hist(y, bins=50, alpha=0.5, label='target')\n",
    "\n",
    "plt.title('Histogram of Model Outputs vs. Labels')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "# Display R2 score in the legend or title if needed\n",
    "plt.legend(title=f'R2 Score: {r2:.2f}')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
